"""
InsightAgent: Generates natural language insights for a DataFrame using profiling and LLM.
"""

from backend.agents.base_agent import BaseAgent
import pandas as pd
import json
import os
from openai import OpenAI
from config.settings import load_prompt
from langsmith import traceable
from backend.core.logging import logger
from typing import Any, Dict

openai_api_key = os.getenv("OPENAI_API_KEY")


class InsightAgent(BaseAgent):
    name = "InsightAgent"
    role = "Generates natural language insights for a DataFrame."    def __init__(self, df: pd.DataFrame):
        """
        Initialize the InsightAgent with a DataFrame.
        Args:
            df (pd.DataFrame): The data to analyze.
        """
        self.df = df
        logger.info(f"[InsightAgent] Initialized with DataFrame shape: {df.shape}")
          @traceable(name="generate_insights")
    def generate_summary(self, query: str = "") -> str:
        """
        Generate a summary of the DataFrame using profiling and LLM.
        Args:
            query (str, optional): The user's query to guide the insight generation.
        Returns:
            str: The generated summary from the LLM.
        Raises:
            Exception: If the LLM call or profiling fails.
        """
        logger.info(f"[InsightAgent] generate_summary called with query: {query}")
        try:
            # Prepare a profiling summary of the data
            profile = {
                "columns": list(self.df.columns),
                "shape": self.df.shape,
                "summary_stats": self.df.describe().to_dict(),
                "missing": self.df.isnull().sum().to_dict(),
            }
            
            template = load_prompt("config/prompts/insight_prompt.txt")
            # Pass the user's query or a default instruction if no query is provided
            prompt = template.format(
                profile=json.dumps(profile, indent=2),
                query=query if query else "Generate general insights about this data."
            )

            client = OpenAI(api_key=openai_api_key)
            logger.info(f"[InsightAgent] Prompt sent to OpenAI.")
            response = client.chat.completions.create(
                model="gpt-4", messages=[{"role": "user", "content": prompt}]
            )
            logger.info(f"[InsightAgent] OpenAI response received.")
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"[InsightAgent] Exception: {e}")
            raise    def run(self, query: str, data: pd.DataFrame, **kwargs) -> Dict[str, Any]:
        """
        Run the InsightAgent to generate insights based on the query and data provided.
        Args:
            query (str): The query or task to perform.
            data (pd.DataFrame): The data to analyze.
        Returns:
            Dict[str, Any]: A dictionary containing the agent name, role, and the result of the insight generation.
        """
        logger.info(f"[InsightAgent] run called with query: {query}")
        try:
            # Pass the query to generate_summary for insight generation
            result = {
                "agent": self.name,
                "role": self.role,
                "output": self.generate_summary(query),  # Pass the query to the summary generation
            }
            logger.info(f"[InsightAgent] run result: {result}")
            return result
        except Exception as e:
            logger.error(f"[InsightAgent] Exception in run: {e}")
            raise
